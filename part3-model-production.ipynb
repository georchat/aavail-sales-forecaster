{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./documentation/images/ibm-logo.png\" alt=\"ibm-logo\" align=\"center\" style=\"width: 200px;\"/>\n",
    "\n",
    "**AI ENTERPRISE WORKFLOW CERTIFICATION**\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Capstone Project - Model Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build a draft version of an API with train, predict, and logfile endpoints.\n",
    "2. Using Docker, bundle your API, model, and unit tests.\n",
    "3. Using test-driven development iterate on your API in a way that anticipates scale, load, and drift.\n",
    "4. Create a post-production analysis script that investigates the relationship between model performance and the business metric.\n",
    "5. Articulate your summarized findings in a final report.\n",
    "\n",
    "At a higher level you are being asked to:\n",
    "\n",
    "1. Ready your model for deployment\n",
    "2. Query your API with new data and test your monitoring tools\n",
    "3. Compare your results to the gold standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import argparse\n",
    "from flask import Flask, jsonify, request\n",
    "from flask import render_template\n",
    "import joblib\n",
    "import socket\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## import model specific functions and variables\n",
    "from modelling import *\n",
    "from logger import *\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello():\n",
    "    html = \"<h3>Hello {name}!</h3>\" \\\n",
    "           \"<b>Hostname:</b> {hostname}<br/>\"\n",
    "    return html.format(name=os.getenv(\"NAME\", \"world\"), hostname=socket.gethostname())\n",
    "\n",
    "@app.route('/predict', methods=['GET','POST'])\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    basic predict function for the API\n",
    "    \"\"\"\n",
    "    \n",
    "    ## input checking\n",
    "    if not request.json:\n",
    "        print(\"ERROR: API (predict): did not receive request data\")\n",
    "        return jsonify([])\n",
    "    \n",
    "    if 'country' not in request.json:\n",
    "        print(\"ERROR API (predict): received request, but no 'country' found within\")\n",
    "        return jsonify(False)\n",
    "        \n",
    "    if 'year' not in request.json:\n",
    "        print(\"ERROR API (predict): received request, but no 'year' found within\")\n",
    "        return jsonify(False)\n",
    "        \n",
    "    if 'month' not in request.json:\n",
    "        print(\"ERROR API (predict): received request, but no 'month' found within\")\n",
    "        return jsonify(False)\n",
    "        \n",
    "    if 'day' not in request.json:\n",
    "        print(\"ERROR API (predict): received request, but no 'day' found within\")\n",
    "        return jsonify(False)\n",
    "    \n",
    "    if 'dev' not in request.json:\n",
    "        print(\"ERROR API (predict): received request, but no 'dev' found within\")\n",
    "        return jsonify([])\n",
    "    \n",
    "    if 'verbose' not in request.json:\n",
    "        print(\"WARNING API (predict): received request, but no 'verbose' found within\")\n",
    "        verbose = 'True'\n",
    "    else:\n",
    "        verbose = request.json['verbose']\n",
    "        \n",
    "    ## predict\n",
    "    _result = result = model_predict(year=request.json['year'],\n",
    "                                     month=request.json['month'],\n",
    "                                     day=request.json['day'],\n",
    "                                     country=request.json['country'],\n",
    "                                     dev=request.json['dev']==\"True\",\n",
    "                                     verbose=verbose==\"True\")\n",
    "    \n",
    "    result = {}\n",
    "    ## convert numpy objects so ensure they are serializable\n",
    "    for key,item in _result.items():\n",
    "        if isinstance(item,np.ndarray):\n",
    "            result[key] = item.tolist()\n",
    "        else:\n",
    "            result[key] = item\n",
    "\n",
    "    return(jsonify(result))\n",
    "\n",
    "@app.route('/train', methods=['GET','POST'])\n",
    "def train():\n",
    "    \"\"\"\n",
    "    basic train function for the API\n",
    "\n",
    "    the 'dev' give you the ability to toggle between a DEV version and a PROD verion of training\n",
    "    \"\"\"\n",
    "\n",
    "    if not request.json:\n",
    "        print(\"ERROR: API (train): did not receive request data\")\n",
    "        return jsonify(False)\n",
    "\n",
    "    if 'dev' not in request.json:\n",
    "        print(\"ERROR API (train): received request, but no 'dev' found within\")\n",
    "        return jsonify(False)\n",
    "    \n",
    "    if 'verbose' not in request.json:\n",
    "        print(\"WARNING API (predict): received request, but no 'verbose' found within\")\n",
    "        verbose = 'True'\n",
    "    else:\n",
    "        verbose = request.json['verbose']\n",
    "\n",
    "    print(\"... training model\")\n",
    "    model = model_train(dev=request.json['dev']==\"True\", verbose=verbose==\"True\")\n",
    "    print(\"... training complete\")\n",
    "\n",
    "    return(jsonify(True))\n",
    "\n",
    "@app.route('/logging', methods=['GET','POST'])\n",
    "def load_logs():\n",
    "    \"\"\"\n",
    "    basic logging function for the API\n",
    "    \"\"\"\n",
    "\n",
    "    if not request.json:\n",
    "        print(\"ERROR: API (train): did not receive request data\")\n",
    "        return jsonify(False)\n",
    "\n",
    "    if 'env' not in request.json:\n",
    "        print(\"ERROR API (log): received request, but no 'env' found within\")\n",
    "        return jsonify(False)\n",
    "        \n",
    "    if 'type' not in request.json:\n",
    "        print(\"ERROR API (log): received request, but no 'type' found within\")\n",
    "        return jsonify(False)\n",
    "        \n",
    "    if 'month' not in request.json:\n",
    "        print(\"ERROR API (log): received request, but no 'month' found within\")\n",
    "        return jsonify(False)\n",
    "        \n",
    "    if 'year' not in request.json:\n",
    "        print(\"ERROR API (log): received request, but no 'year' found within\")\n",
    "        return jsonify(False)\n",
    "    \n",
    "    print(\"... fetching logfile\")\n",
    "    logfile = log_load(env=request.json['env'],\n",
    "                       tag=request.json['type'],\n",
    "                       year=request.json['year'],\n",
    "                       month=request.json['month'])\n",
    "    \n",
    "    result = {}\n",
    "    result[\"logfile\"]=logfile\n",
    "    return(jsonify(result))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ## parse arguments for debug mode\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-d\", \"--debug\", action=\"store_true\", help=\"debug flask\")\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    if args[\"debug\"]:\n",
    "        app.run(debug=True, port=8080)\n",
    "    else:\n",
    "        app.run(host='0.0.0.0', threaded=True ,port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the Flask API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the project directory I started the app:\n",
    "\n",
    "```bash\n",
    "$ python app.py\n",
    "```\n",
    "\n",
    "Then went to [http://localhost:8080/](http://localhost:8080/).\n",
    "\n",
    "I ran the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API predict\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "query = {\"year\":\"2018\",\"month\":\"1\",\"day\":\"5\",\"country\":\"total\",\"dev\":\"True\",\"verbose\":\"True\"}\n",
    "port = 8080\n",
    "r = requests.post('http://localhost:{}/predict'.format(port),json=query)\n",
    "response = literal_eval(r.text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API train\n",
    "query = {\"dev\":\"True\",\"verbose\":\"True\"}\n",
    "port = 8080\n",
    "r = requests.post('http://localhost:{}/train'.format(port),json=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API logging\n",
    "query = {\"env\":\"test\",\"type\":\"train\",\"year\":\"2020\",\"month\":\"5\"}\n",
    "port = 8080\n",
    "r = requests.post('http://localhost:{}/logging'.format(port),json=query)\n",
    "response = literal_eval(r.text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I stopped the server.  We will relaunch it in a few moments from within Docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./unittests/__init__.py\n",
    "\n",
    "import unittest\n",
    "import getopt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "## parse inputs\n",
    "try:\n",
    "    optlist, args = getopt.getopt(sys.argv[1:],'v')\n",
    "except getopt.GetoptError:\n",
    "    print(getopt.GetoptError)\n",
    "    print(sys.argv[0] + \"-v\")\n",
    "    print(\"... the verbose flag (-v) may be used\")\n",
    "    sys.exit()\n",
    "\n",
    "VERBOSE = False\n",
    "RUNALL = False\n",
    "\n",
    "sys.path.append(os.path.realpath(os.path.dirname(__file__)))\n",
    "\n",
    "for o, a in optlist:\n",
    "    if o == '-v':\n",
    "        VERBOSE = True\n",
    "\n",
    "## api tests\n",
    "from ApiTests import *\n",
    "ApiTestSuite = unittest.TestLoader().loadTestsFromTestCase(ApiTest)\n",
    "\n",
    "## model tests\n",
    "from ModelTests import *\n",
    "ModelTestSuite = unittest.TestLoader().loadTestsFromTestCase(ModelTest)\n",
    "\n",
    "## logger tests\n",
    "from LoggerTests import *\n",
    "LoggerTestSuite = unittest.TestLoader().loadTestsFromTestCase(LoggerTest)\n",
    "\n",
    "MainSuite = unittest.TestSuite([ApiTestSuite,ModelTestSuite,LoggerTestSuite])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./unittests/ModelTests.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "model tests\n",
    "\"\"\"\n",
    "\n",
    "import unittest\n",
    "from modelling import *\n",
    "\n",
    "class ModelTest(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    test the essential functionality\n",
    "    \"\"\"\n",
    "    \n",
    "    def test_01_train(self):\n",
    "        \"\"\"\n",
    "        test the train functionality\n",
    "        \"\"\"\n",
    "    \n",
    "        ## train the model\n",
    "        model_train(verbose=False)\n",
    "        \n",
    "        prefix = \"test\" if DEV else \"prod\"\n",
    "        models = [f for f in os.listdir(MODEL_DIR) if re.search(prefix,f)]\n",
    "        self.assertEqual(len(models),11)\n",
    "        \n",
    "    def test_02_load(self):\n",
    "        \"\"\"\n",
    "        test the train functionality\n",
    "        \"\"\"\n",
    "        \n",
    "        ## load the model\n",
    "        models = model_load(verbose=False)\n",
    "        \n",
    "        for tag, model in models.items():\n",
    "            self.assertTrue(\"predict\" in dir(model))\n",
    "            self.assertTrue(\"fit\" in dir(model))\n",
    "        \n",
    "    def test_03_predict(self):\n",
    "        \"\"\"\n",
    "        test the predict function input\n",
    "        \"\"\"\n",
    "    \n",
    "        ## query inputs\n",
    "        query = \"2018\", \"1\", \"5\", \"total\"\n",
    "        \n",
    "        ## load model first\n",
    "        result = model_predict(year=query[0], month=query[1], day=query[2], country=query[3], verbose=False)\n",
    "        y_pred = result[\"y_pred\"]\n",
    "        self.assertTrue(y_pred.dtype==np.float64)\n",
    "            \n",
    "    def test_04_predict(self):\n",
    "        \"\"\"\n",
    "        test the predict function accuracy\n",
    "        \"\"\"\n",
    "    \n",
    "        ## example predict\n",
    "        example_queries = [(\"2018\", \"1\", \"5\", \"total\"),\n",
    "                           (\"2019\", \"2\", \"5\", \"eire\"),\n",
    "                           (\"2018\", \"12\", \"5\", \"france\")]\n",
    "        \n",
    "        for query in example_queries:\n",
    "            result = model_predict(year=query[0], month=query[1], day=query[2], country=query[3], verbose=False)\n",
    "            y_pred = result[\"y_pred\"]\n",
    "            self.assertTrue(y_pred.dtype==np.float64)\n",
    "            \n",
    "## run the tests\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./unittests/ModelTests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./unittests/LoggerTests.py\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "logger tests\n",
    "\"\"\"\n",
    "\n",
    "import unittest\n",
    "## import model specific functions and variables\n",
    "from logger import *\n",
    "\n",
    "class LoggerTest(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    test the essential log functionality\n",
    "    \"\"\"\n",
    "        \n",
    "    def test_01_train(self):\n",
    "        \"\"\"\n",
    "        test the train functionality\n",
    "        \"\"\"\n",
    "\n",
    "        ## train logfile\n",
    "        today = date.today()\n",
    "        logfile = \"{}-train-{}-{}.log\".format(\"test\",today.year,today.month)\n",
    "        log_path = os.path.join(LOG_DIR, logfile)\n",
    "        \n",
    "        self.assertTrue(os.path.exists(log_path))\n",
    "\n",
    "    def test_02_predict(self):\n",
    "        \"\"\"\n",
    "        test the predict functionality\n",
    "        \"\"\"\n",
    "        \n",
    "        ## train logfile\n",
    "        today = date.today()\n",
    "        logfile = \"{}-predict-{}-{}.log\".format(\"test\",today.year,today.month)\n",
    "        log_path = os.path.join(LOG_DIR, logfile)\n",
    "        \n",
    "        self.assertTrue(os.path.exists(log_path))\n",
    "\n",
    "    def test_03_load(self):\n",
    "        \"\"\"\n",
    "        test the load functionality\n",
    "        \"\"\"\n",
    "\n",
    "        ## load model first\n",
    "        logfile = log_load(env=\"test\",tag=\"train\",year=2020,month=5, verbose=False)\n",
    "        logpath = os.path.join(LOG_DIR, logfile)\n",
    "        with open(logpath, \"r\") as log:\n",
    "            text = log.read()\n",
    "        self.assertTrue(len(text.split(\"\\n\"))>2)\n",
    "\n",
    "        \n",
    "### Run the tests\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./unittests/LoggerTests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./unittests/ApiTests.py\n",
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "api tests\n",
    "\n",
    "these tests use the requests package however similar requests can be made with curl\n",
    "\n",
    "e.g.\n",
    "data = '{\"key\":\"value\"}'\n",
    "curl -X POST -H \"Content-Type: application/json\" -d \"%s\" http://localhost:8080/predict'%(data)\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import unittest\n",
    "import requests\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "port = 8080\n",
    "\n",
    "try:\n",
    "    requests.post('http://localhost:{}/predict'.format(port))\n",
    "    server_available = True\n",
    "except:\n",
    "    server_available = False\n",
    "    \n",
    "## test class for the main window function\n",
    "class ApiTest(unittest.TestCase):\n",
    "    \"\"\"\n",
    "    test the essential functionality\n",
    "    \"\"\"\n",
    "    \n",
    "    @unittest.skipUnless(server_available,\"local server is not running\")\n",
    "    def test_predict(self):\n",
    "        \"\"\"\n",
    "        test the predict functionality\n",
    "        \"\"\"\n",
    "        \n",
    "        query = {\"year\":\"2018\",\"month\":\"1\",\"day\":\"5\",\"country\":\"total\",\"dev\":\"True\",\"verbose\":\"True\"}\n",
    "        r = requests.post('http://localhost:{}/predict'.format(port),json=query)\n",
    "        response = literal_eval(r.text)\n",
    "        self.assertTrue(isinstance(response[\"y_pred\"][0], float))\n",
    "\n",
    "    @unittest.skipUnless(server_available,\"local server is not running\")\n",
    "    def test_train(self):\n",
    "        \"\"\"\n",
    "        test the train functionality\n",
    "        \"\"\"\n",
    "      \n",
    "        query = {\"dev\":\"True\",\"verbose\":\"False\"}\n",
    "        r = requests.post('http://localhost:{}/train'.format(port),json=query)\n",
    "        train_complete = re.sub(\"\\W+\",\"\",r.text)\n",
    "        self.assertEqual(train_complete,'true')\n",
    "        \n",
    "    @unittest.skipUnless(server_available,\"local server is not running\")\n",
    "    def test_logging(self):\n",
    "        \"\"\"\n",
    "        test the logging functionality\n",
    "        \"\"\"\n",
    "        \n",
    "        query = {\"env\":\"test\",\"type\":\"train\",\"year\":\"2020\",\"month\":\"5\"}\n",
    "        r = requests.post('http://localhost:{}/logging'.format(port),json=query)\n",
    "        response = literal_eval(r.text)\n",
    "        self.assertEqual(response.get(\"logfile\"),'test-train-2020-5.log')\n",
    "\n",
    "### Run the tests\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./unittests/ApiTests.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run-tests.py\n",
    "#!/usr/bin/python \n",
    "\n",
    "import sys\n",
    "import unittest\n",
    "\n",
    "from unittests import *\n",
    "unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run Unit Tests with a single script**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "    ~$ python run-tests.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Docker File**\n",
    "\n",
    "Before we build the DockerFile first we need to create a requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "\n",
    "cython\n",
    "numpy\n",
    "flask\n",
    "pandas\n",
    "scikit-learn\n",
    "matplotlib\n",
    "IPython\n",
    "seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "# Use an official Python runtime as a parent image\n",
    "FROM python:3.7.5-stretch\n",
    "\n",
    "RUN apt-get update && apt-get install -y \\\n",
    "python3-dev \\\n",
    "build-essential    \n",
    "        \n",
    "# Set the working directory to /app\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the current directory contents into the container at /app\n",
    "ADD . /app\n",
    "\n",
    "# Install any needed packages specified in requirements.txt\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Make port 80 available to the world outside this container\n",
    "EXPOSE 80\n",
    "\n",
    "# Define environment variable\n",
    "ENV NAME World\n",
    "\n",
    "# Run app.py when the container launches\n",
    "CMD [\"python\", \"app.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the Docker image and run it**\n",
    "\n",
    "Step one: build the image (from the directory that was created with this notebook)\n",
    " \n",
    "```bash\n",
    "    ~$ docker build -t capstone-ml-app .\n",
    "```\n",
    "\n",
    "Check that the image is there.\n",
    "\n",
    "```bash\n",
    "    ~$ docker image ls\n",
    "```\n",
    "\n",
    "You may notice images that you no longer use.  You may delete them with\n",
    "\n",
    "```bash\n",
    "    ~$ docker image rm IMAGE_ID_OR_NAME\n",
    "```\n",
    "\n",
    "Run the container\n",
    "\n",
    "```bash\n",
    "docker run -p 4000:8080 capstone-ml-app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the running app**\n",
    "\n",
    "First go to [http://localhost:4000/](http://localhost:4000/) to ensure the app is running and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API predict\n",
    "\n",
    "query = {\"year\":\"2018\",\"month\":\"1\",\"day\":\"5\",\"country\":\"total\",\"dev\":\"True\",\"verbose\":\"True\"}\n",
    "port = 4000\n",
    "r = requests.post('http://localhost:{}/predict'.format(port),json=query)\n",
    "response = literal_eval(r.text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API logging\n",
    "\n",
    "query = {\"env\":\"test\",\"type\":\"train\",\"year\":\"2020\",\"month\":\"5\"}\n",
    "port = 4000\n",
    "r = requests.post('http://localhost:{}/logging'.format(port),json=query)\n",
    "response = literal_eval(r.text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Production Analysis - Perfomance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting monitoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile monitoring.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_engineering import engineer_features\n",
    "from modelling import _model_train, model_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from scipy.stats import wasserstein_distance\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## switch to production\n",
    "DEV = False\n",
    "\n",
    "def simulate_samples(n_samples, X, y, dates):\n",
    "    \"\"\"\n",
    "    simulate new samples (via bootstrap)\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = np.arange(y.size)\n",
    "    new_indices = np.random.choice(indices, n_samples, replace=True)\n",
    "    \n",
    "    X_new = X[new_indices,:]\n",
    "    y_new = y[new_indices]\n",
    "    dates_new = dates[new_indices]\n",
    "    return X_new, y_new, dates_new\n",
    "\n",
    "\n",
    "def model_monitor(country=\"total\", dev=DEV, training=True):\n",
    "    \"\"\"\n",
    "    performance monitoring\n",
    "    \"\"\"\n",
    "    print(\"Monitor Model\")\n",
    "    \n",
    "    ## import data\n",
    "    datasets = engineer_features(training=training, dev=dev)\n",
    "    X, y, dates, labels = datasets[country]\n",
    "    dates = pd.to_datetime(dates)\n",
    "    print(X.shape)\n",
    "    \n",
    "    ## train the model\n",
    "    if training:\n",
    "        _model_train(X, y, labels, tag=country, dev=dev)\n",
    "    \n",
    "    ## monitor RMSE\n",
    "    samples = [10, 20, 30, 50, 60]\n",
    "\n",
    "    for n in samples:\n",
    "        X_new, y_new, dates_new = simulate_samples(n, X, y, dates)\n",
    "        queries = [(str(d.year), str(d.month), str(d.day), country) for d in dates_new]\n",
    "        y_pred = [model_predict(year=query[0], month=query[1], day=query[2], country=query[3],verbose=False, dev=dev)[\"y_pred\"][0].round(2) for query in queries]\n",
    "        rmse = np.sqrt(mean_squared_error(y_new.tolist(),y_pred))\n",
    "        print(\"RSME: {}\".format(rmse.round(2)))\n",
    "        \n",
    "    ## monitor performance\n",
    "    ## scaling\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    samples = [25, 50, 75, 90]\n",
    "\n",
    "    clf_y = EllipticEnvelope(random_state=0,contamination=0.01)\n",
    "    clf_X = EllipticEnvelope(random_state=0,contamination=0.01)\n",
    "\n",
    "    clf_X.fit(X)\n",
    "    clf_y.fit(y.reshape(y.size,1))\n",
    "\n",
    "    results = defaultdict(list)\n",
    "    for n in samples:\n",
    "        X_new, y_new, dates_new = simulate_samples(n,X,y, dates)\n",
    "        results[\"sample_size\"].append(n)\n",
    "        results['wasserstein_X'].append(np.round(wasserstein_distance(X.flatten(),X_new.flatten()),2))\n",
    "        results['wasserstein_y'].append(np.round(wasserstein_distance(y,y_new),2))\n",
    "        test1 = clf_X.predict(X_new)\n",
    "        test2 = clf_y.predict(y_new.reshape(y_new.size,1))\n",
    "        results[\"outlier_percent_X\"].append(np.round(1.0 - (test1[test1==1].size / test1.size),2))\n",
    "        results[\"outlier_percent_y\"].append(np.round(1.0 - (test2[test2==1].size / test2.size),2))\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    run_start = time.time()\n",
    "  \n",
    "    ## monitor model\n",
    "    result = model_monitor(dev=DEV)\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    m, s = divmod(time.time()-run_start,60)\n",
    "    h, m = divmod(m, 60)\n",
    "    print(\"...running time:\", \"%d:%02d:%02d\"%(h, m, s))\n",
    "    \n",
    "    print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run monitoring.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor Model\n",
      "Ingesting Data\n",
      "...loading timeseries data from files\n",
      "Creating Feature Matrix\n",
      "Engineering Features and Target\n",
      "(98, 9)\n",
      "...training model: 4/4\n",
      "...best model:Random Forest\n",
      "...updating train log\n",
      "RSME: 3993.39\n",
      "RSME: 4745.31\n",
      "RSME: 10383.61\n",
      "RSME: 9009.92\n",
      "RSME: 4399.97\n"
     ]
    }
   ],
   "source": [
    "from monitoring import model_monitor\n",
    "\n",
    "results_df = model_monitor(dev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 100.0%, transparent 100.0%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 100.0%, transparent 100.0%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col3 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col4 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, red 50.0%, red 90.0%, transparent 90.0%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 74.1%, transparent 74.1%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 76.2%, transparent 76.2%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col3 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col4 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 66.7%, transparent 66.7%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 68.1%, transparent 68.1%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col3 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col4 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, red 50.0%, red 65.0%, transparent 65.0%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 66.7%, transparent 66.7%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col2 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, lightblue 50.0%, lightblue 69.9%, transparent 69.9%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col3 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, red 50.0%, red 55.0%, transparent 55.0%);\n",
       "        }    #T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col4 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg, transparent 50.0%, red 50.0%, red 55.0%, transparent 55.0%);\n",
       "        }</style><table id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0d\" ><caption>Performance Monitoring</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >sample_size</th>        <th class=\"col_heading level0 col1\" >wasserstein_X</th>        <th class=\"col_heading level0 col2\" >wasserstein_y</th>        <th class=\"col_heading level0 col3\" >outlier_percent_X</th>        <th class=\"col_heading level0 col4\" >outlier_percent_y</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col0\" class=\"data row0 col0\" >25</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col1\" class=\"data row0 col1\" >0.270000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col2\" class=\"data row0 col2\" >18247.120000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow0_col4\" class=\"data row0 col4\" >0.080000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col0\" class=\"data row1 col0\" >50</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col1\" class=\"data row1 col1\" >0.130000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col2\" class=\"data row1 col2\" >9555.220000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col0\" class=\"data row2 col0\" >75</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col1\" class=\"data row2 col1\" >0.090000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col2\" class=\"data row2 col2\" >6594.860000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow2_col4\" class=\"data row2 col4\" >0.030000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col0\" class=\"data row3 col0\" >90</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col1\" class=\"data row3 col1\" >0.090000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col2\" class=\"data row3 col2\" >7278.820000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col3\" class=\"data row3 col3\" >0.010000</td>\n",
       "                        <td id=\"T_db9ae8b8_91cb_11ea_b475_a08cfd2abf0drow3_col4\" class=\"data row3 col4\" >0.010000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x205723dd188>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(results_df\n",
    " .style\n",
    " .hide_index()\n",
    " .bar(color='lightblue', vmin=0, subset=['wasserstein_X'], align='zero')\n",
    " .bar(color='lightblue', vmin=0, subset=['wasserstein_y'], align='zero')\n",
    " .bar(color='red', vmin=0, vmax=0.1,subset=['outlier_percent_X'], align='zero')\n",
    " .bar(color='red', vmin=0, vmax=0.1,subset=['outlier_percent_y'], align='zero')\n",
    " .set_caption('Performance Monitoring'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
